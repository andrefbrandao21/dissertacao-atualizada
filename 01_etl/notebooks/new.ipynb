{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca2e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merge conclu√≠do com sucesso!\n",
      "üìä Munic√≠pios finais: 5570\n",
      "üìå Chave id_municipio padronizada como String (7 d√≠gitos).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def limpar_id(series):\n",
    "    \"\"\"\n",
    "    Padroniza o ID do munic√≠pio: remove decimais (.0), \n",
    "    converte para inteiro e preenche com zeros √† esquerda (7 d√≠gitos).\n",
    "    \"\"\"\n",
    "    return pd.to_numeric(series, errors='coerce').fillna(0).astype(int).astype(str).str.zfill(7)\n",
    "\n",
    "def carregar_e_preparar_dados():\n",
    "    \"\"\"Carrega as bases brutas e processadas aplicando a limpeza de IDs.\"\"\"\n",
    "    # 1. Base do Pix (Cross-Section)\n",
    "    df_pix = pd.read_parquet('../data/processed/intensidade_pix_municipios.parquet')\n",
    "    df_pix['id_municipio'] = limpar_id(df_pix['id_municipio'])\n",
    "\n",
    "    # 2. Covari√°veis (Socioecon√¥micas e Geo)\n",
    "    df_covar = pd.read_parquet('../data/raw/covariaveis_municipais.parquet')\n",
    "    df_covar['id_municipio'] = limpar_id(df_covar['id_municipio'])\n",
    "\n",
    "    # 3. Homic√≠dios (Ipeadata)\n",
    "    df_homic = pd.read_csv('../data/processed/homicidios_ipeadata.csv', skiprows=1, sep=',')\n",
    "    df_homic = df_homic.rename(columns={'2019': 'taxa_homicidio', 'C√≥digo': 'cod_raw'})\n",
    "    df_homic['id_municipio'] = limpar_id(df_homic['cod_raw'])\n",
    "    \n",
    "    return df_pix, df_covar, df_homic\n",
    "\n",
    "def realizar_merges(df_pix, df_covar, df_homic):\n",
    "    \"\"\"Executa a uni√£o das bases e cria a coluna de macrorregi√£o.\"\"\"\n",
    "    # Pix + Covari√°veis\n",
    "    cols_drop = ['nome', 'sigla_uf', 'populacao', 'Municipio', 'Estado']\n",
    "    df_final = df_pix.merge(\n",
    "        df_covar.drop(columns=cols_drop, errors='ignore'), \n",
    "        on='id_municipio', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Adi√ß√£o dos Homic√≠dios\n",
    "    df_final = df_final.merge(\n",
    "        df_homic[['id_municipio', 'taxa_homicidio']], \n",
    "        on='id_municipio', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # CRIAR COLUNA DE MACRORREGI√ÉO (D√≠gito 1 do ID IBGE)\n",
    "    # 1: Norte, 2: Nordeste, 3: Sudeste, 4: Sul, 5: Centro-Oeste\n",
    "    df_final['cod_regiao'] = df_final['id_municipio'].str[0]\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def tratar_e_salvar(df_final, output_path):\n",
    "    \"\"\"Trata valores ausentes e salva o arquivo final em parquet.\"\"\"\n",
    "    cols_num = [\n",
    "        'taxa_homicidio', 'pib_per_capita', 'idhm_e', \n",
    "        'densidade_tel', 'populacao', 'longitude', 'latitude'\n",
    "    ]\n",
    "\n",
    "    for col in cols_num:\n",
    "        if col in df_final.columns:\n",
    "            df_final[col] = pd.to_numeric(df_final[col], errors='coerce').fillna(0)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df_final.to_parquet(output_path, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Merge conclu√≠do com sucesso!\")\n",
    "    print(f\"üìä Coluna 'cod_regiao' criada para Exact Match.\")\n",
    "    print(f\"üìå Arquivo salvo em: {output_path}\")\n",
    "\n",
    "def main():\n",
    "    output_path = '../data/processed/dataset_final_matching.parquet'\n",
    "    df_pix, df_covar, df_homic = carregar_e_preparar_dados()\n",
    "    df_final = realizar_merges(df_pix, df_covar, df_homic)\n",
    "    tratar_e_salvar(df_final, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando processamento...\n",
      "üìä Gerando grupos de tratamento (Tercis, Quartis e Quintis)...\n",
      "‚úÖ Processo conclu√≠do!\n",
      "üìÇ Salvo em: ../data/processed/intensidade_pix_municipios.parquet\n",
      "üìà Munic√≠pios processados: 5570\n",
      "üîù M√°ximo Intensidade: 1.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6dd0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# --- CONFIGURA√á√ÉO DE CAMINHOS ---\n",
    "INPUT_FILE = '../data/raw/test.parquet'\n",
    "OUTPUT_DIR = '../data/processed'\n",
    "OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'rais_painel_balanceado.parquet')\n",
    "\n",
    "def processar_rais_otimizado(path):\n",
    "    \"\"\"\n",
    "    L√™ apenas colunas necess√°rias e usa vetoriza√ß√£o para economizar RAM.\n",
    "    \"\"\"\n",
    "    print(\"   [1/3] Lendo colunas selecionadas e mapeando setores...\")\n",
    "    \n",
    "    # L√™ apenas o necess√°rio\n",
    "    cols = ['id_municipio', 'cnae_2', 'ano', 'quantidade_vinculos_ativos']\n",
    "    df = pd.read_parquet(path, columns=cols)\n",
    "\n",
    "    # Vetoriza√ß√£o em vez de apply: muito mais r√°pido e leve\n",
    "    # CNAE Divis√£o (2 d√≠gitos)\n",
    "    div = (df['cnae_2'].fillna(0).astype(np.int32) // 1000)\n",
    "    \n",
    "    df['setor'] = 'Outros'\n",
    "    df.loc[div.between(1, 3), 'setor'] = 'Agro'\n",
    "    df.loc[div.between(5, 33), 'setor'] = 'Industria'\n",
    "    df.loc[div == 84, 'setor'] = 'Setor Publico'\n",
    "    df.loc[div.between(35, 99), 'setor'] = 'Servicos'\n",
    "    \n",
    "    # Remove coluna tempor√°ria e libera mem√≥ria\n",
    "    df.drop(columns=['cnae_2'], inplace=True)\n",
    "\n",
    "    print(\"   [2/3] Agregando estoque...\")\n",
    "    df_agg = (df.groupby(['id_municipio', 'setor', 'ano'], as_index=False)\n",
    "                ['quantidade_vinculos_ativos'].sum())\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "    return df_agg\n",
    "\n",
    "def rebalancear_painel_otimizado(df_agg):\n",
    "    \"\"\"\n",
    "    Usa tipos de dados categ√≥ricos para reduzir o tamanho do produto cartesiano.\n",
    "    \"\"\"\n",
    "    print(\"   [3/3] Rebalanceando o painel...\")\n",
    "\n",
    "    # Remover 'Outros' antes de balancear economiza mem√≥ria\n",
    "    df_agg = df_agg[df_agg['setor'] != 'Outros'].copy()\n",
    "\n",
    "    todos_municipios = df_agg['id_municipio'].unique()\n",
    "    todos_setores = ['Agro', 'Industria', 'Servicos', 'Setor Publico']\n",
    "    todos_anos = df_agg['ano'].unique()\n",
    "\n",
    "    # Criar index e esqueleto\n",
    "    index = pd.MultiIndex.from_product(\n",
    "        [todos_municipios, todos_setores, todos_anos], \n",
    "        names=['id_municipio', 'setor', 'ano']\n",
    "    )\n",
    "    \n",
    "    # Reindex √© mais eficiente que Merge para balanceamento\n",
    "    df_final = (df_agg.set_index(['id_municipio', 'setor', 'ano'])\n",
    "                      .reindex(index, fill_value=0)\n",
    "                      .reset_index())\n",
    "\n",
    "    # Vari√°vel para DID\n",
    "    df_final['log_estoque'] = np.log1p(df_final['quantidade_vinculos_ativos'].astype(np.float32))\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "def main():\n",
    "    print(\"--- INICIANDO ETL RAIS OTIMIZADO ---\")\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"ERRO: Arquivo de entrada n√£o encontrado: {INPUT_FILE}\")\n",
    "        return\n",
    "\n",
    "    # Processamento em etapas com limpeza de cache\n",
    "    df_agg = processar_rais_otimizado(INPUT_FILE)\n",
    "    df_final = rebalancear_painel_otimizado(df_agg)\n",
    "    \n",
    "    print(f\"Salvando em: {OUTPUT_FILE}\")\n",
    "    # compress√£o snappy √© padr√£o e r√°pida\n",
    "    df_final.to_parquet(OUTPUT_FILE, index=False, compression='snappy')\n",
    "    print(\"--- CONCLU√çDO ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed66446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_simples_base(path, dtypes):\n",
    "    df = pd.read_csv(path, sep=\";\", encoding=\"latin-1\", header=None, \n",
    "                     usecols=[0, 4, 5, 6], names=[\"cnpj_basico\", \"mei\", \"ini\", \"fim\"],\n",
    "                     dtype=dtypes)\n",
    "    df = df[df[\"mei\"] == \"S\"].copy()\n",
    "    df['ano_ini'] = (df['ini'] // 10000).fillna(0).astype(\"int16\")\n",
    "    df['ano_fim'] = (df['fim'] // 10000).fillna(0).astype(\"int16\")\n",
    "    return df.drop(columns=[\"mei\", \"ini\", \"fim\"])\n",
    "\n",
    "def classify_sector(df):\n",
    "    divisao = (df['cnae'] // 100000).fillna(0).astype(int)\n",
    "    df['setor'] = 'Servicos'\n",
    "    df.loc[divisao.between(1, 3), 'setor'] = 'Agro'\n",
    "    df.loc[divisao.between(5, 33), 'setor'] = 'Industria'\n",
    "    df.loc[divisao == 84, 'setor'] = 'Setor Publico'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcb8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001b[32m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[0m|\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def fetch_pix_data(data_base: str):\n",
    "    \"\"\"Obt√©m dados da API do BCB para um m√™s espec√≠fico (YYYYMM).\"\"\"\n",
    "    url = f\"https://olinda.bcb.gov.br/olinda/servico/Pix_DadosAbertos/versao/v1/odata/TransacoesPixPorMunicipio(DataBase=@DataBase)?@DataBase='{data_base}'&$format=json\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json().get('value', [])\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro na requisi√ß√£o: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_to_parquet(data, output_path):\n",
    "    \"\"\"Converte para DataFrame e salva em Parquet.\"\"\"\n",
    "    if not data:\n",
    "        return\n",
    "    df = pd.DataFrame(data)\n",
    "    out = Path(output_path)\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(out, index=False)\n",
    "    print(f\"Salvo: {out} ({len(df)} registros)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemplo de uso\n",
    "    mes = '202011'\n",
    "    raw_data = fetch_pix_data(mes)\n",
    "    save_to_parquet(raw_data, '../data/raw/dados_pix.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5a0bb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m, in \u001b[0;36mfetch_pix_data\u001b[1;34m(data_base)\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(url)\n",
      "\u001b[0;32m      6\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n",
      "\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErro na requisi√ß√£o: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[1;32m---> 11\u001b[0m \u001b[43mfetch_pix_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m202011\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m, in \u001b[0;36mfetch_pix_data\u001b[1;34m(data_base)\u001b[0m\n",
      "\u001b[0;32m      6\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n",
      "\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErro na requisi√ß√£o: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "def fetch_pix_data(data_base: str):\n",
    "    \"\"\"Obt√©m dados da API do BCB para um m√™s espec√≠fico (YYYYMM).\"\"\"\n",
    "    url = f\"https://olinda.bcb.gov.br/olinda/servico/Pix_DadosAbertos/versao/v1/odata/TransacoesPixPorMunicipio(DataBase=@DataBase)?@DataBase='{data_base}'&$format=json\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json().get('value', [])\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro na requisi√ß√£o: {e}\")\n",
    "        return []\n",
    "fetch_pix_data('202011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cria a coluna unificada pegando o valor que existir\n",
    "df['escolaridade'] = df['grau_instrucao_1985_2005'].fillna(df['grau_instrucao_apos_2005'])\n",
    "\n",
    "# 2. Remove as colunas antigas para limpar o df\n",
    "df.drop(columns=['grau_instrucao_1985_2005', 'grau_instrucao_apos_2005'], inplace=True)\n",
    "\n",
    "# 3. Agrupa novamente para consolidar as linhas (necess√°rio se os IDs eram diferentes)\n",
    "df = df.groupby(['ano', 'sigla_uf', 'id_municipio', 'municipio_nome', 'escolaridade'], as_index=False)['total_vinculos'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9144bf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001b[32m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[0m|\n"
     ]
    }
   ],
   "source": [
    "import basedosdados as bd\n",
    "\n",
    "billing_id = 'dissertacao-pnate'\n",
    "\n",
    "query = \"\"\"\n",
    "  SELECT\n",
    "    dados.ano as ano,\n",
    "    dados.sigla_uf AS sigla_uf,\n",
    "    diretorio_sigla_uf.nome AS sigla_uf_nome,\n",
    "    dados.id_municipio AS id_municipio,\n",
    "    diretorio_id_municipio.nome AS id_municipio_nome,\n",
    "    dados.populacao as populacao\n",
    "FROM `basedosdados.br_ibge_populacao.municipio` AS dados\n",
    "LEFT JOIN (SELECT DISTINCT sigla,nome  FROM `basedosdados.br_bd_diretorios_brasil.uf`) AS diretorio_sigla_uf\n",
    "    ON dados.sigla_uf = diretorio_sigla_uf.sigla\n",
    "LEFT JOIN (SELECT DISTINCT id_municipio,nome  FROM `basedosdados.br_bd_diretorios_brasil.municipio`) AS diretorio_id_municipio\n",
    "    ON dados.id_municipio = diretorio_id_municipio.id_municipio\n",
    "\"\"\"\n",
    "\n",
    "df = bd.read_sql(query = query, billing_project_id = billing_id)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
